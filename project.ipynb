{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42hqOfqEeJoO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob, h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data on jupyter hub..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Labels\n",
    "\n",
    "### (1) Detection matches catalog entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddzT_7PrpMvm"
   },
   "source": [
    "### Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "pL48n_ypooL_",
    "outputId": "f8df9d82-cdf1-40c9-a179-474bd606abd6"
   },
   "outputs": [],
   "source": [
    "CAT_PATH = 'data/stationary_catalogs/stationary_catalog_0931_g.fits' # or whatever path\n",
    "cat = fits.open(CAT_PATH)\n",
    "# later incorporate these headers somehow?\n",
    "# cat[0].header "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract catalog data into numpy ndarray (This is pretty quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_ndarray(cat):\n",
    "    ''' Input: cat - opened .fits catalog file\n",
    "        Output: X - NxM ndarray (N=num entries, M=relavant columns)\n",
    "                cat_cols - column names'''\n",
    "    cat_cols = cat[1].data.columns.names\n",
    "    cat_cols = cat_cols[:3] # only interested in first 3 cols\n",
    "\n",
    "    data = cat[1].data\n",
    "    X = np.array([data[c] for c in cat_cols]).T # ndarray of the 3 cols\n",
    "    return X, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>Dec</th>\n",
       "      <th>MAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215.580332</td>\n",
       "      <td>-19.576746</td>\n",
       "      <td>17.720699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215.581094</td>\n",
       "      <td>-19.683190</td>\n",
       "      <td>22.907400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215.580419</td>\n",
       "      <td>-19.629544</td>\n",
       "      <td>23.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215.580366</td>\n",
       "      <td>-19.622345</td>\n",
       "      <td>23.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215.581000</td>\n",
       "      <td>-19.700400</td>\n",
       "      <td>20.313400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RA        Dec        MAG\n",
       "0  215.580332 -19.576746  17.720699\n",
       "1  215.581094 -19.683190  22.907400\n",
       "2  215.580419 -19.629544  23.144400\n",
       "3  215.580366 -19.622345  23.122900\n",
       "4  215.581000 -19.700400  20.313400"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with fits.open(CAT_PATH) as cat:\n",
    "    cat_X, cat_cols = cat_to_ndarray(cat)\n",
    "\n",
    "cat_df = pd.DataFrame(cat_X, columns=cat_cols)\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJIOzrBTeJoX"
   },
   "outputs": [],
   "source": [
    "chips=['XY01', 'XY02', 'XY03', 'XY04', 'XY05', 'XY06',\n",
    "       'XY10', 'XY11', 'XY12', 'XY13', 'XY14', 'XY15', 'XY16', 'XY17',\n",
    "       'XY20', 'XY21', 'XY22', 'XY23', 'XY24', 'XY25', 'XY26', 'XY27',\n",
    "       'XY30', 'XY31', 'XY32', 'XY33', 'XY34', 'XY35', 'XY36', 'XY37',\n",
    "       'XY40', 'XY41', 'XY42', 'XY43', 'XY44', 'XY45', 'XY46', 'XY47',\n",
    "       'XY50', 'XY51', 'XY52', 'XY53', 'XY54', 'XY55', 'XY56', 'XY57',\n",
    "       'XY60', 'XY61', 'XY62', 'XY63', 'XY64', 'XY65', 'XY66', 'XY67',\n",
    "       'XY71', 'XY72', 'XY73', 'XY74', 'XY75', 'XY76']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need all the columns\n",
    "# hdus[chips[0]+'.psf'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract detection data into numpy ndarray (This is not so quick, but workable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smf_to_ndarray(hdus, labeled=False):\n",
    "    columns = ['RA_PSF', 'DEC_PSF', 'CAL_PSF_MAG', 'CAL_PSF_MAG_SIG']\n",
    "    if labeled:\n",
    "        columns.extend(['MATCH', 'EDGE'])\n",
    "    chip_data = []\n",
    "    for chip in chips:\n",
    "        data = hdus[chip+'.psf'].data\n",
    "        data = np.array([data[c] for c in columns]).T\n",
    "        chip_data.append(data)\n",
    "    X = np.concatenate(chip_data, axis=0)\n",
    "    return X, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELED_PATH = 'data/labeled_smf/'\n",
    "\n",
    "smf_files = glob.glob(LABELED_PATH+'*.smf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "for smf in smf_files:\n",
    "    with fits.open(SMF_PATH) as hdus:\n",
    "        X, columns = smf_to_ndarray(hdus, labeled=True)\n",
    "        #X = clean(X)\n",
    "    Xs.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SMF_PATH = 'data/smf/o6771g0234o.729155.cm.943415.smf'\n",
    "\n",
    "# SMF_PATH = 'data/labeled_smf/o6771g0234o.729155.cm.943415_label.smf'\n",
    "\n",
    "# with fits.open(SMF_PATH) as hdus:\n",
    "#     X, columns = smf_to_ndarray(hdus, labeled=True)\n",
    "    \n",
    "# # detect_df = pd.DataFrame(X, columns=columns)\n",
    "# # detect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(Xs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "\n",
    "remove NaNs and Infinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(X):\n",
    "    '''Remove all rows from ndarray if any entries are nan or inf'''\n",
    "    isnan = np.isnan(X).any(axis=1)\n",
    "    isinf = np.isinf(X).any(axis=1)\n",
    "    bad_idxs = np.any([isnan, isinf], axis=0)\n",
    "    cleaned = X[~bad_idxs]\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first just assume MATCH == real detection\n",
    "MATCH_IDX = -2\n",
    "\n",
    "y = X[:,MATCH_IDX]\n",
    "X = np.delete(X, MATCH_IDX,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_arr(arr, name):\n",
    "    with h5py.File(name+'.h5', 'w') as file:\n",
    "        file.create_dataset(name, data=arr)\n",
    "    \n",
    "def read_arr(arr, name):\n",
    "    with h5py.File(name+'.h5', 'r') as file:\n",
    "        data = file[name][:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_arr(X, 'X')\n",
    "write_arr(y, 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105532, 5), (105532,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegressionCV(cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = log_model.predict(X_train)\n",
    "train_acc = (y_train == y_train_pred).sum() / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = log_model.predict(X_test)\n",
    "test_acc = (y_test == y_test_pred).sum() / y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6601315240874805, 0.658050333535476)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/labeled_smf/o6771g0234o.729155.cm.943415_label.smf',\n",
       " 'data/labeled_smf/o6776g0273o.730768.cm.946329_label.smf']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Detection to Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detections have a CAL_PSF_MAG_SIGMA that we might want to use (rather than arbitrary tolerance) when checking if a magnitutes are \"matches\" but this is more involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sketch...\n",
    "# basically create a gaussian with magnitute mu and sigma from detection\n",
    "# and see if a catalog entry is within a given percentile of that gaussian\n",
    "mu = detect_X[:,2]\n",
    "sig = detect_X[:,3]\n",
    "PERCENTILE = 0.95\n",
    "conf_ints = norm(mu,sig).interval(PERCENTILE)\n",
    "conf_ints = np.array(conf_ints).T\n",
    "cat_mag = cat_df['MAG']\n",
    "for lower, upper in conf_ints:\n",
    "    lower <= cat_mag[0] <= upper # not complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpler:\n",
    "\n",
    "Compare detection and catalog entry elements (RA, DEC, MAG) using allclose()\n",
    "and arbitrary tolerance\n",
    "\n",
    "But this process appears *far too slow!* :'("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOLERANCE = 1e-05\n",
    "def get_comp_func(d):\n",
    "    ''' Creates a comparison function for a given detection\n",
    "        It can then be applied across the catalog'''\n",
    "    d = d[:3] #only concerned with RA, DEC, and MAG\n",
    "    def comp_func(c):\n",
    "        return np.allclose(d, c, rtol=TOLERANCE)\n",
    "    return comp_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_all(compare, cats):\n",
    "    for c in cats:\n",
    "        if compare(c):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for d in detect_X[:10]:\n",
    "    compare = get_comp_func(d)\n",
    "    result = check_all(compare, cat_X)\n",
    "    results.append(result)\n",
    "\n",
    "# z = np.apply_along_axis(compare, 1, cat_X[:50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results.csv', results, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cs109b_group48_milestone2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
